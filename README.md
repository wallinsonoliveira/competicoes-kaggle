## Competi√ß√µes no Kaggle

#### Kaggle √© uma plataforma online popular para cientistas de dados e entusiastas de machine learning, que oferece uma variedade de recursos e oportunidades para aprender, competir e colaborar em projetos de ci√™ncia de dados. 
Processos utilizados: Defini√ß√£o do Problema, Coleta de Dados, An√°lise de Dados, Pr√©-processamento de Dados, Feature Engineering, Divis√£o dos Dados, Escolha do Modelo, Treinamento do Modelo, Avalia√ß√£o do Modelo, Vari√°veis mais Importantes (Permuta√ß√£o), Ajuste de Hiperpar√¢metros, Implementa√ß√£o e Monitoramento, Interpreta√ß√£o e Comunica√ß√£o dos Resultados.

DataSet estudados e submetidos:

### üö¢ Titanic
A base de dados do Titanic, frequentemente usada em competi√ß√µes e tutoriais de ci√™ncia de dados, cont√©m informa√ß√µes sobre os passageiros do famoso navio que naufragou em 1912. Este conjunto de dados √© amplamente utilizado para praticar e aprender t√©cnicas de an√°lise de dados, estat√≠stica e machine learning. Saiba mais em: https://www.kaggle.com/competitions/titanic. Caderno/C√≥digos: https://www.kaggle.com/code/peeweesuper/titanic-wallinson. Algoritmos usados: Regress√£o Log√≠stica, KNN, Decision Tree, Random Forest, SVM, Naive Bayes, Gradient Boosting, AdaBoost, Extra Trees, Bagging, Perceptron, MLP Classifier, QDA, XGBoost, LightGBM, CatBoost, Voting Classifier e Stacking. Meu Score: ***78,468%***

### üçæ Wine Quality
Esse conjunto de dados √© amplamente empregado em estudos de machine learning, pois fornece uma oportunidade de praticar algoritmos de regress√£o e classifica√ß√£o, especialmente no contexto de classifica√ß√£o ordinal, onde as classes possuem uma ordem natural, mas as dist√¢ncias entre elas n√£o s√£o necessariamente uniformes. Saiba mais em: https://www.kaggle.com/competitions/playground-series-s3e5. Caderno/C√≥digos: https://www.kaggle.com/code/peeweesuper/wine-quality-wallinson. Algoritmos usados: Regress√£o Log√≠stica, KNN, Decision Tree, Random Forest, SVM, Naive Bayes, Gradient Boosting, AdaBoost, Extra Trees, Bagging, Perceptron, MLP Classifier, QDA, XGBoost, LightGBM, CatBoost, Voting Classifier e Stacking. Meu Score P√∫blico: ***58,203%*** (176¬∫/903) - Score Privado: ***54,715%*** (306¬∫/903).
